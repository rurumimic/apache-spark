# Kubernetes

[Running Spark on Kubernetes](https://spark.apache.org/docs/latest/running-on-kubernetes.html)

## Prerequisites

- Spark 2.3+
- Kubernetes 1.6+
  - 3 CPU & 4GB RAM

## How it works

![](https://spark.apache.org/docs/latest/img/k8s-cluster-mode.png)

## Submitting Applications to Kubernetes

### Download

```bash
curl -O http://mirror.navercorp.com/apache/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
tar zxvf spark-2.4.5-bin-hadoop2.7.tgz
```

### Docker Images

Location: `kubernetes/dockerfiles/spark`

Run:

```bash
bin/docker-image-tool.sh -r <repo> -t my-tag build
bin/docker-image-tool.sh -r <repo> -t my-tag push
```

Example:

```bash
bin/docker-image-tool.sh build
```

```bash
docker images
REPOSITORY    TAG       IMAGE ID        CREATED               SIZE
spark-r       latest    c69edbc544af    12 seconds ago        1.11GB
spark-py      latest    7df17ad75afe    About a minute ago    1.06GB
spark         latest    1fcc7075a892    3 minutes ago         555MB
```

### Cluster Mode

Discover the apiserver URL:

```bash
kubectl cluster-info

Kubernetes master is running at https://kubernetes.docker.internal:6443
```

```bash
kubectl proxy

Starting to serve on 127.0.0.1:8001
```

```bash
kubectl create serviceaccount spark
kubectl create rolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
```

```bash
bin/spark-submit \
    --master k8s://http://127.0.0.1:8001 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.container.image=spark:latest \
    local://$SPARK_HOME/examples/jars/spark-examples_2.11-2.4.5.jar
```

bin/spark-submit \
    --master k8s://http://127.0.0.1:8001 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.container.image=spark:latest \
    local://Users/dodo/code/rurumimic/apache-spark/download/spark-2.4.5-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.5.jar

bin/spark-submit \
    --master k8s://http://127.0.0.1:8001 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.container.image=spark:latest \
    examples/jars/spark-examples_2.11-2.4.5.jar

docker run --rm -it --net host spark:latest spark-submit \
    --master k8s://https://kubernetes.docker.internal:6443 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.container.image=spark:latest \
    $SPARK_HOME/examples/jars/spark-examples_2.11-2.4.5.jar 100

bin/spark-submit \
    --master k8s://http://127.0.0.1:8001 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.container.image=spark:latest \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    examples/jars/spark-examples_2.11-2.4.5.jar 100

docker run --rm -ti --net host gradiant/spark:2.4.0 spark-submit \
    --master k8s://https://kubernetes.docker.internal:6443 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.container.image=gradiant/spark:2.4.0 \
    --conf spark.kubernetes.executor.request.cores=0.2 \
    --executor-memory 500M \
    examples/jars/spark-examples_2.11-2.4.5.jar 100