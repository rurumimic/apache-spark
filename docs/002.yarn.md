# Yarn

[Running Spark on YARN](https://spark.apache.org/docs/latest/running-on-yarn.html)

## ENV

```bash
vi $SPARK_HOME/conf/spark-env.sh
```

```bash
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
```

## Examples

```bash
spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
--driver-memory 4g \
--executor-memory 2g \
--executor-cores 1 \
$SPARK_HOME/examples/jars/spark-examples*.jar \
10

Pi is roughly 3.1421711421711422
```

- cluster: `$HADOOP_HOME/logs/userlogs/<application_ID>`

### Memory Error

```bash
Failing this attempt.Diagnostics: Container [pid=8536,containerID=container_1584426065386_0017_01_000001] is running beyond virtual memory limits. Current usage: 223.0 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
```

```bash
vi $HADOOP_HOME/etc/hadoop/yarn-site.xml
```

```bash
stop-yarn.sh
start-yarn.sh
```

## Cluster

```bash
start-master.sh
start-slave.sh localhost:7077
```

```bash
spark-submit --master spark://localhost:7077 $SPARK_HOME/examples/src/main/python/pi.py 10

Pi is roughly 3.143272
```
